{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18e874a9-28f4-4006-ab69-649e817c5089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading volume mesh...\n",
      "Reading file: C:\\Users\\shubh\\Documents\\Analytics\\FOS WS\\Mesh Files\\mesh.vtk\n",
      "Volume mesh loaded successfully.\n",
      "Assigning material properties...\n",
      "Material properties assigned.\n",
      "Computing global stiffness matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/6924336 [00:16<13:55:34, 138.11it/s]"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not pickle the task to send it to the workers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\shubh\\anaconda3\\envs\\FEM\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\queues.py\", line 159, in _feed\n    obj_ = dumps(obj, reducers=reducers)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\shubh\\anaconda3\\envs\\FEM\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 215, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File \"C:\\Users\\shubh\\anaconda3\\envs\\FEM\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 208, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File \"C:\\Users\\shubh\\anaconda3\\envs\\FEM\\Lib\\site-packages\\joblib\\externals\\cloudpickle\\cloudpickle.py\", line 1245, in dump\n    return super().dump(obj)\n           ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\shubh\\anaconda3\\envs\\FEM\\Lib\\site-packages\\pyvista\\core\\dataobject.py\", line 728, in __getstate__\n    raise TypeError(f'Cannot pickle dataset of type {self.GetDataObjectType()}')\n                                                     ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\shubh\\anaconda3\\envs\\FEM\\Lib\\site-packages\\pyvista\\core\\dataobject.py\", line 67, in __getattr__\n    return super().__getattribute__(item)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'Cell' object has no attribute 'GetDataObjectType'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 155\u001b[0m\n\u001b[0;32m    152\u001b[0m assign_material_properties(mesh, cohesion, friction_angle, density, E, nu)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# Compute the global stiffness matrix\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m K_global \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_global_stiffness_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnu\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 128\u001b[0m, in \u001b[0;36mcompute_global_stiffness_matrix\u001b[1;34m(mesh, E, nu)\u001b[0m\n\u001b[0;32m    125\u001b[0m K_global \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcoo_matrix((mesh\u001b[38;5;241m.\u001b[39mn_points \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m, mesh\u001b[38;5;241m.\u001b[39mn_points \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Parallel processing over cells\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_and_assemble_for_cell\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmesh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_cell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK_global\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmesh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_cells\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# Combine results\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m K_part \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\FEM\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\FEM\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\FEM\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\FEM\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\FEM\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\FEM\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mPicklingError\u001b[0m: Could not pickle the task to send it to the workers."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import meshio  # Replace PyVista with Meshio\n",
    "\n",
    "# Load Volume Mesh using Meshio\n",
    "def load_volume_mesh(filepath):\n",
    "    print(\"Loading volume mesh...\")\n",
    "    mesh = meshio.read(filepath)\n",
    "    print(\"Volume mesh loaded successfully.\")\n",
    "    \n",
    "    # Extract points and cells from the mesh\n",
    "    points = np.array(mesh.points)\n",
    "    cells = np.array(mesh.cells_dict['tetra'])  # Assuming a tetrahedral mesh\n",
    "    return points, cells\n",
    "\n",
    "# Assign Material Properties\n",
    "def assign_material_properties(cells, cohesion, friction_angle, density, E, nu):\n",
    "    print(\"Assigning material properties...\")\n",
    "    \n",
    "    # Create arrays to store material properties for each cell\n",
    "    material_props = {\n",
    "        'cohesion': np.full(cells.shape[0], cohesion),\n",
    "        'friction_angle': np.full(cells.shape[0], friction_angle),\n",
    "        'density': np.full(cells.shape[0], density),\n",
    "        'E': np.full(cells.shape[0], E),\n",
    "        'nu': np.full(cells.shape[0], nu)\n",
    "    }\n",
    "    \n",
    "    print(\"Material properties assigned.\")\n",
    "    return material_props\n",
    "\n",
    "# Compute Jacobian\n",
    "def compute_jacobian(element_nodes, dN_dxi):\n",
    "    J = np.zeros((3, 3))  # 3x3 for a 3D element\n",
    "    for i in range(4):  # Assuming a 4-node tetrahedral element\n",
    "        J += np.outer(dN_dxi[i], element_nodes[i])\n",
    "    return J\n",
    "\n",
    "# Compute B Matrix\n",
    "def compute_B_matrix(J_inv, dN_dxi):\n",
    "    B = np.zeros((6, 12))  # 6 strains and 3 displacements per node, 4 nodes * 3 = 12\n",
    "    for i in range(4):\n",
    "        dN_dx = np.dot(J_inv, dN_dxi[i])\n",
    "        B[0, i*3] = dN_dx[0]  # ε_xx\n",
    "        B[1, i*3+1] = dN_dx[1]  # ε_yy\n",
    "        B[2, i*3+2] = dN_dx[2]  # ε_zz\n",
    "        B[3, i*3] = dN_dx[1]  # ε_xy\n",
    "        B[3, i*3+1] = dN_dx[0]\n",
    "        B[4, i*3+1] = dN_dx[2]  # ε_yz\n",
    "        B[4, i*3+2] = dN_dx[1]\n",
    "        B[5, i*3] = dN_dx[2]  # ε_zx\n",
    "        B[5, i*3+2] = dN_dx[0]\n",
    "    return B\n",
    "\n",
    "# Compute C Matrix\n",
    "def compute_C_matrix(E, nu):\n",
    "    C = np.zeros((6, 6))  # 6x6 matrix for 3D stress-strain relationship\n",
    "    factor = E / (1 + nu) / (1 - 2 * nu)\n",
    "    C[0, 0] = C[1, 1] = C[2, 2] = factor * (1 - nu)\n",
    "    C[3, 3] = C[4, 4] = C[5, 5] = E / 2 / (1 + nu)\n",
    "    C[0, 1] = C[1, 0] = C[0, 2] = C[2, 0] = C[1, 2] = C[2, 1] = factor * nu\n",
    "    return C\n",
    "\n",
    "# Compute Element Stiffness\n",
    "def compute_element_stiffness(E, nu, element_nodes):\n",
    "    dN_dxi = np.array([\n",
    "        [-1, -1, -1],\n",
    "        [1, 0, 0],\n",
    "        [0, 1, 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    J = compute_jacobian(element_nodes, dN_dxi)\n",
    "    det_J = np.linalg.det(J)\n",
    "    \n",
    "    if np.abs(det_J) < 1e-12:\n",
    "        print(\"Warning: Degenerate element detected. Skipping element.\")\n",
    "        return None\n",
    "    \n",
    "    J_inv = np.linalg.inv(J)\n",
    "    B = compute_B_matrix(J_inv, dN_dxi)\n",
    "    C = compute_C_matrix(E, nu)\n",
    "    K_elem = np.dot(B.T, np.dot(C, B)) * det_J\n",
    "    return K_elem\n",
    "\n",
    "# Assemble Global Stiffness Matrix Efficiently\n",
    "def assemble_global_stiffness_efficient(K_global, K_elem, element):\n",
    "    num_dofs_per_node = 3\n",
    "    num_nodes = len(element)\n",
    "    global_indices = np.array([int(node * num_dofs_per_node) for node in element], dtype=np.int32)\n",
    "    \n",
    "    data = []\n",
    "    rows = []\n",
    "    cols = []\n",
    "    \n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            global_i = global_indices[i]\n",
    "            global_j = global_indices[j]\n",
    "            \n",
    "            for k in range(num_dofs_per_node):\n",
    "                for l in range(num_dofs_per_node):\n",
    "                    value = K_elem[i*num_dofs_per_node+k, j*num_dofs_per_node+l]\n",
    "                    data.append(value)\n",
    "                    rows.append(global_i+k)\n",
    "                    cols.append(global_j+l)\n",
    "    \n",
    "    data = np.array(data)\n",
    "    rows = np.array(rows)\n",
    "    cols = np.array(cols)\n",
    "    \n",
    "    # Use SciPy's sparse matrix addition\n",
    "    K_global += sp.coo_matrix((data, (rows, cols)), shape=K_global.shape).tocsr()\n",
    "    return K_global\n",
    "\n",
    "# Parallel function to compute stiffness for each cell\n",
    "def compute_and_assemble_for_cell(E, nu, cell_point_ids, cell_nodes):\n",
    "    K_elem = compute_element_stiffness(E, nu, cell_nodes)\n",
    "    if K_elem is not None:\n",
    "        return (cell_point_ids, K_elem)\n",
    "    return None\n",
    "\n",
    "# Compute Global Stiffness Matrix using joblib\n",
    "def compute_global_stiffness_matrix(points, cells, E, nu):\n",
    "    print(\"Computing global stiffness matrix...\")\n",
    "\n",
    "    # Preprocess the cells: extract point_ids and node coordinates\n",
    "    cells_data = [(cell, points[cell]) for cell in cells]\n",
    "\n",
    "    # Initialize global stiffness matrix as a sparse COO matrix\n",
    "    K_global = sp.coo_matrix((points.shape[0] * 3, points.shape[0] * 3))\n",
    "    \n",
    "    # Parallel processing over cells\n",
    "    results = Parallel(n_jobs=-1)(delayed(compute_and_assemble_for_cell)(E, nu, cell_point_ids, cell_nodes) for cell_point_ids, cell_nodes in tqdm(cells_data))\n",
    "    \n",
    "    # Combine results\n",
    "    for result in results:\n",
    "        if result is not None:\n",
    "            cell_point_ids, K_elem = result\n",
    "            K_global = assemble_global_stiffness_efficient(K_global, K_elem, cell_point_ids)\n",
    "\n",
    "    print(\"Global stiffness matrix computed.\")\n",
    "    return K_global.tocsr()  # Convert to CSR format after assembly\n",
    "\n",
    "# --- Main script starts here ---\n",
    "\n",
    "# Material properties\n",
    "cohesion = 0  # Cohesion in Pascals\n",
    "friction_angle = 10  # Friction angle in degrees\n",
    "density = 1500  # Density in kg/m³\n",
    "E = 1000  # Young's modulus in Pascals\n",
    "nu = 0.3  # Poisson's ratio\n",
    "\n",
    "# Load the volume mesh\n",
    "filepath = r\"C:\\Users\\shubh\\Documents\\Analytics\\FOS WS\\Mesh Files\\mesh.vtk\"\n",
    "points, cells = load_volume_mesh(filepath)\n",
    "\n",
    "# Assign material properties\n",
    "material_props = assign_material_properties(cells, cohesion, friction_angle, density, E, nu)\n",
    "\n",
    "# Compute the global stiffness matrix\n",
    "K_global = compute_global_stiffness_matrix(points, cells, E, nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c09992-acb3-4110-a180-517cee10e39f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
